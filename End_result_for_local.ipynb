{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb76373c-a590-4dae-9b60-33862bfd4bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initializing enhanced dashboard...\n",
      "INFO:__main__:✓ Speech recognition available\n",
      "INFO:__main__:✓ Text-to-speech available\n",
      "INFO:__main__:Starting system initialization...\n",
      "INFO:__main__:✓ Added Python REPL and Bash tools\n",
      "INFO:__main__:Started MCP event loop thread\n",
      "INFO:langchain_mcp_tools.langchain_mcp_tools:MCP server \"local_http\": initializing with: {'url': 'http://127.0.0.1:8000/mcp'}\n",
      "INFO:langchain_mcp_tools.langchain_mcp_tools:MCP server \"local_http\": Pre-validating authentication\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:langchain_mcp_tools.langchain_mcp_tools:MCP server \"local_http\": error during initialization: MCP server \"local_http\": Connection failed: All connection attempts failed\n",
      "ERROR:__main__:MCP initialization failed: MCP server \"local_http\": Connection failed: All connection attempts failed\n",
      "INFO:__main__:Continuing without MCP tools...\n",
      "INFO:__main__:✓ Created agent: Data Analyst with 2 tools: ['python_repl', 'bash_command']\n",
      "INFO:__main__:✓ Created agent: Python Coder with 2 tools: ['python_repl', 'bash_command']\n",
      "INFO:__main__:✓ Created agent: Assistant with 0 tools: []\n",
      "INFO:__main__:✓ System initialization complete\n",
      "/tmp/ipykernel_26549/54127133.py:730: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://e49987cddd686d3b71.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e49987cddd686d3b71.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing: 'hi\n",
      "...' with Data Analyst\n",
      "INFO:__main__:Invoking agent executor for: hi\n",
      "...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Agent executor returned: <class 'dict'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:TTS error: [Errno 2] No such file or directory: 'ffprobe'\n",
      "INFO:__main__:Processing: 'hey how are you...' with Data Analyst\n",
      "INFO:__main__:Invoking agent executor for: hey how are you...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Agent executor returned: <class 'dict'>\n",
      "ERROR:__main__:TTS error: [Errno 2] No such file or directory: 'ffprobe'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help you with any questions or tasks you have. How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing: 'hey how are you...' with Data Analyst\n",
      "INFO:__main__:Invoking agent executor for: hey how are you...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Agent executor returned: <class 'dict'>\n",
      "ERROR:__main__:TTS error: [Errno 2] No such file or directory: 'ffprobe'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI'm here and ready to assist you! How can I help you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing: 'can you test the audio...' with Data Analyst\n",
      "INFO:__main__:Invoking agent executor for: can you test the audio...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Agent executor returned: <class 'dict'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI don't have the capability to test audio directly. However, I can guide you through the process of testing audio on your device. Let me know what you need help with!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:TTS error: [Errno 2] No such file or directory: 'ffprobe'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "import numpy as np\n",
    "import os\n",
    "import threading\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import logging\n",
    "import warnings\n",
    "import sys\n",
    "import json\n",
    "import io\n",
    "import contextlib\n",
    "import dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "# Suppress httpcore warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "logging.getLogger(\"httpcore\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Apply nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Core imports\n",
    "from langchain_mcp_tools import convert_mcp_to_langchain_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# Import LangChain's built-in tools\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_community.tools import ShellTool\n",
    "\n",
    "class SimpleAudio:\n",
    "    \"\"\"Simplified audio handler\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.has_stt = False\n",
    "        self.has_tts = False\n",
    "        self._check_audio()\n",
    "        \n",
    "    def _check_audio(self):\n",
    "        \"\"\"Check audio capabilities\"\"\"\n",
    "        try:\n",
    "            import speech_recognition as sr\n",
    "            self.recognizer = sr.Recognizer()\n",
    "            self.has_stt = True\n",
    "            logger.info(\"✓ Speech recognition available\")\n",
    "        except:\n",
    "            logger.warning(\"✗ Speech recognition not available\")\n",
    "            \n",
    "        try:\n",
    "            import edge_tts\n",
    "            self.has_tts = True\n",
    "            logger.info(\"✓ Text-to-speech available\")\n",
    "        except:\n",
    "            logger.warning(\"✗ Text-to-speech not available\")\n",
    "    \n",
    "    def transcribe(self, audio_data):\n",
    "        \"\"\"Transcribe audio\"\"\"\n",
    "        if not self.has_stt or audio_data is None:\n",
    "            return \"\"\n",
    "            \n",
    "        try:\n",
    "            import speech_recognition as sr\n",
    "            \n",
    "            if isinstance(audio_data, tuple):\n",
    "                sr_rate, audio_array = audio_data\n",
    "                \n",
    "                if len(audio_array) == 0:\n",
    "                    return \"\"\n",
    "                    \n",
    "                if audio_array.dtype != np.int16:\n",
    "                    audio_array = (audio_array * 32767).astype(np.int16)\n",
    "                \n",
    "                import io, wave\n",
    "                buffer = io.BytesIO()\n",
    "                with wave.open(buffer, 'wb') as wav:\n",
    "                    wav.setnchannels(1)\n",
    "                    wav.setsampwidth(2)\n",
    "                    wav.setframerate(sr_rate)\n",
    "                    wav.writeframes(audio_array.tobytes())\n",
    "                \n",
    "                buffer.seek(0)\n",
    "                \n",
    "                with sr.AudioFile(buffer) as source:\n",
    "                    audio = self.recognizer.record(source)\n",
    "                    return self.recognizer.recognize_google(audio)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Transcription error: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def speak(self, text):\n",
    "        \"\"\"Generate speech\"\"\"\n",
    "        if not self.has_tts:\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            import edge_tts\n",
    "            import scipy.io.wavfile as wavfile\n",
    "            \n",
    "            async def generate():\n",
    "                tts = edge_tts.Communicate(text, \"en-US-AriaNeural\")\n",
    "                with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as f:\n",
    "                    await tts.save(f.name)\n",
    "                    return f.name\n",
    "            \n",
    "            loop = asyncio.new_event_loop()\n",
    "            try:\n",
    "                mp3_file = loop.run_until_complete(generate())\n",
    "                \n",
    "                # Convert MP3 to WAV\n",
    "                try:\n",
    "                    from pydub import AudioSegment\n",
    "                    audio = AudioSegment.from_mp3(mp3_file)\n",
    "                    wav_file = mp3_file.replace('.mp3', '.wav')\n",
    "                    audio.export(wav_file, format=\"wav\")\n",
    "                    sr, audio_data = wavfile.read(wav_file)\n",
    "                    os.unlink(mp3_file)\n",
    "                    os.unlink(wav_file)\n",
    "                    return sr, audio_data\n",
    "                except ImportError:\n",
    "                    os.unlink(mp3_file)\n",
    "                    logger.warning(\"pydub not installed for audio conversion\")\n",
    "                    return None\n",
    "                    \n",
    "            finally:\n",
    "                loop.close()\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"TTS error: {e}\")\n",
    "            return None\n",
    "\n",
    "class EnhancedMCPDashboard:\n",
    "    \"\"\"Enhanced dashboard with better MCP tool handling and parameter introspection\"\"\"\n",
    "    \n",
    "    def __init__(self, mcp_servers: Dict, agent_configs: List[Dict], max_iterations: int = 5):\n",
    "        logger.info(\"Initializing enhanced dashboard...\")\n",
    "        \n",
    "        self.mcp_servers = mcp_servers\n",
    "        self.agent_configs = agent_configs\n",
    "        self.max_iterations = max_iterations  # Configurable iterations\n",
    "        self.audio = SimpleAudio()\n",
    "        self.agents = {}\n",
    "        self.tools = []\n",
    "        self.mcp_tools_info = {}  # Store MCP tool metadata\n",
    "        self.executors = {}\n",
    "        \n",
    "        # MCP event loop\n",
    "        self.mcp_loop = None\n",
    "        self.mcp_thread = None\n",
    "        self.cleanup_func = None\n",
    "        \n",
    "        # Initialize system\n",
    "        self._initialize_system()\n",
    "        \n",
    "        # Register cleanup\n",
    "        import atexit\n",
    "        atexit.register(self._cleanup)\n",
    "    \n",
    "    def _initialize_system(self):\n",
    "        \"\"\"Initialize all components\"\"\"\n",
    "        logger.info(\"Starting system initialization...\")\n",
    "        \n",
    "        # Initialize tools\n",
    "        self._init_tools()\n",
    "        \n",
    "        # Create agents\n",
    "        self._create_agents()\n",
    "        \n",
    "        logger.info(\"✓ System initialization complete\")\n",
    "    \n",
    "    def _init_tools(self):\n",
    "        \"\"\"Initialize all tools including MCP\"\"\"\n",
    "        # Add LangChain's Python REPL tool with a wrapper to handle parameter format\n",
    "        base_python_tool = PythonREPLTool()\n",
    "        \n",
    "        # Create a wrapper function that handles the parameter format\n",
    "        def python_wrapper(input_data):\n",
    "            \"\"\"Wrapper that handles different input formats for Python REPL\"\"\"\n",
    "            # Handle dict input from agent\n",
    "            if isinstance(input_data, dict):\n",
    "                # Try different possible key names\n",
    "                code = input_data.get('command', input_data.get('code', input_data.get('query', str(input_data))))\n",
    "            else:\n",
    "                code = str(input_data)\n",
    "            \n",
    "            logger.info(f\"Python REPL executing: {code[:100]}...\")\n",
    "            \n",
    "            # Call the actual tool\n",
    "            result = base_python_tool.run(code)\n",
    "            \n",
    "            logger.info(f\"Python REPL result: {result[:200]}...\")\n",
    "            return result\n",
    "        \n",
    "        # Create the wrapped tool\n",
    "        python_tool = Tool(\n",
    "            name=\"python_repl\",\n",
    "            description=\"Execute Python code in a REPL environment. Input should be valid Python code. Returns the output of the code execution.\",\n",
    "            func=python_wrapper\n",
    "        )\n",
    "        self.tools.append(python_tool)\n",
    "        \n",
    "        # Add Shell/Bash tool\n",
    "        shell_tool = ShellTool()\n",
    "        shell_tool.name = \"bash_command\"\n",
    "        shell_tool.description = \"Execute shell commands. Use this to run bash commands, scripts, or interact with the system.\"\n",
    "        self.tools.append(shell_tool)\n",
    "        \n",
    "        logger.info(\"✓ Added Python REPL and Bash tools\")\n",
    "        \n",
    "        # Create a persistent event loop for MCP operations\n",
    "        self.mcp_loop = asyncio.new_event_loop()\n",
    "        self.mcp_thread = threading.Thread(\n",
    "            target=self.mcp_loop.run_forever,\n",
    "            daemon=True,\n",
    "            name=\"MCP-EventLoop\"\n",
    "        )\n",
    "        self.mcp_thread.start()\n",
    "        logger.info(\"Started MCP event loop thread\")\n",
    "        \n",
    "        # Initialize MCP tools\n",
    "        if self.mcp_servers:\n",
    "            try:\n",
    "                # Initialize MCP in the dedicated loop\n",
    "                future = asyncio.run_coroutine_threadsafe(\n",
    "                    self._init_mcp_async(),\n",
    "                    self.mcp_loop\n",
    "                )\n",
    "                mcp_tools, self.cleanup_func = future.result(timeout=30)\n",
    "                \n",
    "                if mcp_tools:\n",
    "                    # Process and wrap each MCP tool\n",
    "                    for tool in mcp_tools:\n",
    "                        # Extract tool metadata for parameter introspection\n",
    "                        self._extract_tool_metadata(tool)\n",
    "                        \n",
    "                        # Wrap the tool with enhanced handling\n",
    "                        wrapped_tool = self._wrap_mcp_tool_enhanced(tool)\n",
    "                        self.tools.append(wrapped_tool)\n",
    "                    \n",
    "                    logger.info(f\"✓ Loaded {len(mcp_tools)} MCP tools: {[t.name for t in mcp_tools]}\")\n",
    "                    \n",
    "                    # Log tool details\n",
    "                    for name, info in self.mcp_tools_info.items():\n",
    "                        logger.info(f\"  - {name}: {info.get('params', 'No params')}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"MCP initialization failed: {e}\")\n",
    "                logger.info(\"Continuing without MCP tools...\")\n",
    "    \n",
    "    def _extract_tool_metadata(self, mcp_tool):\n",
    "        \"\"\"Extract and store metadata about MCP tool parameters\"\"\"\n",
    "        tool_info = {\n",
    "            \"name\": mcp_tool.name,\n",
    "            \"description\": mcp_tool.description,\n",
    "            \"params\": {}\n",
    "        }\n",
    "        \n",
    "        # Try to extract parameter information from the tool\n",
    "        if hasattr(mcp_tool, 'args_schema'):\n",
    "            schema = mcp_tool.args_schema\n",
    "            if hasattr(schema, 'schema'):\n",
    "                schema_dict = schema.schema()\n",
    "                properties = schema_dict.get('properties', {})\n",
    "                required = schema_dict.get('required', [])\n",
    "                \n",
    "                for param_name, param_info in properties.items():\n",
    "                    tool_info[\"params\"][param_name] = {\n",
    "                        \"type\": param_info.get('type', 'string'),\n",
    "                        \"description\": param_info.get('description', ''),\n",
    "                        \"required\": param_name in required,\n",
    "                        \"default\": param_info.get('default', None)\n",
    "                    }\n",
    "        \n",
    "        # If no schema, try to parse from description\n",
    "        elif 'parameter' in mcp_tool.description.lower():\n",
    "            # Simple heuristic to extract parameter names from description\n",
    "            desc_lower = mcp_tool.description.lower()\n",
    "            if 'text' in desc_lower:\n",
    "                tool_info[\"params\"][\"text\"] = {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Text input\",\n",
    "                    \"required\": True\n",
    "                }\n",
    "            elif 'message' in desc_lower:\n",
    "                tool_info[\"params\"][\"message\"] = {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Message input\",\n",
    "                    \"required\": True\n",
    "                }\n",
    "            elif 'input' in desc_lower:\n",
    "                tool_info[\"params\"][\"input\"] = {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Input value\",\n",
    "                    \"required\": True\n",
    "                }\n",
    "        \n",
    "        self.mcp_tools_info[mcp_tool.name] = tool_info\n",
    "        logger.info(f\"Extracted metadata for {mcp_tool.name}: {tool_info['params']}\")\n",
    "    \n",
    "    def _wrap_mcp_tool_enhanced(self, mcp_tool):\n",
    "        \"\"\"Enhanced wrapper for MCP tools with better parameter handling\"\"\"\n",
    "        from langchain.tools import Tool\n",
    "        \n",
    "        tool_metadata = self.mcp_tools_info.get(mcp_tool.name, {})\n",
    "        \n",
    "        def sync_wrapper(*args, **kwargs):\n",
    "            \"\"\"Enhanced synchronous wrapper with parameter introspection\"\"\"\n",
    "            try:\n",
    "                # Log incoming arguments\n",
    "                logger.info(f\"MCP tool '{mcp_tool.name}' called with args={args}, kwargs={kwargs}\")\n",
    "                \n",
    "                # Build proper kwargs based on tool metadata\n",
    "                final_kwargs = {}\n",
    "                \n",
    "                # If we have metadata about parameters\n",
    "                if tool_metadata.get(\"params\"):\n",
    "                    param_info = tool_metadata[\"params\"]\n",
    "                    \n",
    "                    # Handle positional arguments\n",
    "                    if args and not kwargs:\n",
    "                        if len(args) == 1:\n",
    "                            arg = args[0]\n",
    "                            \n",
    "                            # If it's already a dict with the right keys, use it\n",
    "                            if isinstance(arg, dict):\n",
    "                                # Check if dict has the expected parameters\n",
    "                                for param_name in param_info:\n",
    "                                    if param_name in arg:\n",
    "                                        final_kwargs[param_name] = arg[param_name]\n",
    "                                \n",
    "                                # If no matching params found, treat the whole dict as input\n",
    "                                if not final_kwargs:\n",
    "                                    # Find the first required string parameter\n",
    "                                    for param_name, info in param_info.items():\n",
    "                                        if info.get(\"required\") and info.get(\"type\") == \"string\":\n",
    "                                            final_kwargs[param_name] = str(arg)\n",
    "                                            break\n",
    "                            \n",
    "                            # If it's a string, assign to the first string parameter\n",
    "                            elif isinstance(arg, str):\n",
    "                                for param_name, info in param_info.items():\n",
    "                                    if info.get(\"type\") == \"string\":\n",
    "                                        final_kwargs[param_name] = arg\n",
    "                                        break\n",
    "                    \n",
    "                    # Override with any explicit kwargs\n",
    "                    final_kwargs.update(kwargs)\n",
    "                \n",
    "                else:\n",
    "                    # No metadata, use fallback logic\n",
    "                    if args and not kwargs:\n",
    "                        if len(args) == 1:\n",
    "                            if isinstance(args[0], dict):\n",
    "                                final_kwargs = args[0]\n",
    "                            else:\n",
    "                                # Try common parameter names\n",
    "                                final_kwargs = {\"text\": str(args[0])}\n",
    "                    else:\n",
    "                        final_kwargs = kwargs\n",
    "                \n",
    "                # Ensure all required parameters are present\n",
    "                missing_params = []\n",
    "                if tool_metadata.get(\"params\"):\n",
    "                    for param_name, info in tool_metadata[\"params\"].items():\n",
    "                        if info.get(\"required\") and param_name not in final_kwargs:\n",
    "                            # Try to provide a default or raise an error\n",
    "                            if info.get(\"default\") is not None:\n",
    "                                final_kwargs[param_name] = info[\"default\"]\n",
    "                            else:\n",
    "                                missing_params.append(param_name)\n",
    "                \n",
    "                if missing_params:\n",
    "                    error_msg = f\"Missing required parameters for '{mcp_tool.name}': {', '.join(missing_params)}\"\n",
    "                    logger.error(error_msg)\n",
    "                    expected_format = {p: f\"<{info['type']}>\" for p, info in tool_metadata[\"params\"].items() if info.get(\"required\")}\n",
    "                    # Use repr to safely format the JSON without template issues\n",
    "                    return f\"Error: {error_msg}\\nExpected format: \" + repr(expected_format)\n",
    "                \n",
    "                # Log the final call\n",
    "                logger.info(f\"Calling MCP tool '{mcp_tool.name}' with final kwargs: {final_kwargs}\")\n",
    "                \n",
    "                # Submit the async operation to the MCP event loop\n",
    "                future = asyncio.run_coroutine_threadsafe(\n",
    "                    mcp_tool.ainvoke(final_kwargs),\n",
    "                    self.mcp_loop\n",
    "                )\n",
    "                \n",
    "                # Wait for the result\n",
    "                result = future.result(timeout=30)\n",
    "                \n",
    "                logger.info(f\"MCP tool '{mcp_tool.name}' returned: {result}\")\n",
    "                \n",
    "                # Format the result\n",
    "                if isinstance(result, dict):\n",
    "                    return json.dumps(result, indent=2)\n",
    "                elif isinstance(result, (list, tuple)):\n",
    "                    return json.dumps(result, indent=2)\n",
    "                else:\n",
    "                    return str(result)\n",
    "                    \n",
    "            except asyncio.TimeoutError:\n",
    "                error_msg = f\"MCP tool '{mcp_tool.name}' timed out\"\n",
    "                logger.error(error_msg)\n",
    "                return error_msg\n",
    "            except Exception as e:\n",
    "                error_msg = f\"MCP tool '{mcp_tool.name}' error: {str(e)}\"\n",
    "                logger.error(error_msg)\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                return error_msg\n",
    "        \n",
    "        # Create enhanced description with parameter info\n",
    "        enhanced_description = mcp_tool.description\n",
    "        if tool_metadata.get(\"params\"):\n",
    "            param_desc = []\n",
    "            required_params = []\n",
    "            optional_params = []\n",
    "            \n",
    "            for param_name, info in tool_metadata[\"params\"].items():\n",
    "                desc_str = f\"{param_name} ({info['type']})\"\n",
    "                if info.get('description'):\n",
    "                    desc_str += f\": {info['description']}\"\n",
    "                \n",
    "                if info.get(\"required\"):\n",
    "                    required_params.append(desc_str)\n",
    "                else:\n",
    "                    optional_params.append(desc_str)\n",
    "            \n",
    "            if required_params:\n",
    "                enhanced_description += f\"\\nRequired parameters: {', '.join(required_params)}\"\n",
    "            if optional_params:\n",
    "                enhanced_description += f\"\\nOptional parameters: {', '.join(optional_params)}\"\n",
    "        \n",
    "        # Create a new Tool with sync execution\n",
    "        return Tool(\n",
    "            name=mcp_tool.name,\n",
    "            description=enhanced_description,\n",
    "            func=sync_wrapper,\n",
    "            return_direct=False\n",
    "        )\n",
    "    \n",
    "    async def _init_mcp_async(self):\n",
    "        \"\"\"Initialize MCP tools asynchronously\"\"\"\n",
    "        tools, cleanup = await convert_mcp_to_langchain_tools(self.mcp_servers)\n",
    "        return tools, cleanup\n",
    "    \n",
    "    def _create_agents(self):\n",
    "        \"\"\"Create agents with proper tool handling\"\"\"\n",
    "        for config in self.agent_configs:\n",
    "            name = config[\"name\"]\n",
    "            model = config.get(\"model\", \"gpt-4o\")\n",
    "            temperature = config.get(\"temperature\", 0.7)\n",
    "            \n",
    "            # Create LLM\n",
    "            llm = ChatOpenAI(\n",
    "                model=model,\n",
    "                temperature=temperature,\n",
    "                streaming=False,  # Disable streaming for better tool handling\n",
    "                request_timeout=60\n",
    "            )\n",
    "            \n",
    "            # Select tools based on agent type\n",
    "            if name == \"Python Coder\":\n",
    "                # Python coder gets Python REPL and Bash tools\n",
    "                agent_tools = [t for t in self.tools if t.name in [\"python_repl\", \"bash_command\"]]\n",
    "            elif name == \"Data Analyst\":\n",
    "                # Data analyst gets all tools\n",
    "                agent_tools = self.tools\n",
    "            else:\n",
    "                # General assistant gets MCP tools but not code execution\n",
    "                agent_tools = [t for t in self.tools if t.name not in [\"python_repl\", \"bash_command\"]]\n",
    "            \n",
    "            # Create prompt with enhanced instructions\n",
    "            system_message = self._get_enhanced_system_message(name, agent_tools)\n",
    "            prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", system_message),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "                MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "            ])\n",
    "            \n",
    "            # Create agent\n",
    "            agent = create_tool_calling_agent(llm, agent_tools, prompt)\n",
    "            \n",
    "            # Create executor with proper async handling\n",
    "            executor = AgentExecutor(\n",
    "                agent=agent,\n",
    "                tools=agent_tools,\n",
    "                verbose=True,  # Enable verbose for debugging\n",
    "                return_intermediate_steps=True,\n",
    "                max_iterations=self.max_iterations,  # Use configurable iterations\n",
    "                early_stopping_method=\"generate\",\n",
    "                handle_parsing_errors=True\n",
    "            )\n",
    "            \n",
    "            self.executors[name] = executor\n",
    "            self.agents[name] = {\n",
    "                \"executor\": executor,\n",
    "                \"tools\": agent_tools,\n",
    "                \"config\": config\n",
    "            }\n",
    "            \n",
    "            logger.info(f\"✓ Created agent: {name} with {len(agent_tools)} tools: {[t.name for t in agent_tools]}\")\n",
    "    \n",
    "    def _get_enhanced_system_message(self, agent_name: str, tools: List) -> str:\n",
    "        \"\"\"Get enhanced system message with detailed tool instructions\"\"\"\n",
    "        tool_descriptions = []\n",
    "        \n",
    "        for tool in tools:\n",
    "            desc = f\"- {tool.name}: {tool.description}\"\n",
    "            \n",
    "            # Add parameter details for MCP tools\n",
    "            if tool.name in self.mcp_tools_info:\n",
    "                params = self.mcp_tools_info[tool.name].get(\"params\", {})\n",
    "                if params:\n",
    "                    param_list = []\n",
    "                    for param_name, info in params.items():\n",
    "                        req = \"required\" if info.get(\"required\") else \"optional\"\n",
    "                        param_list.append(f\"{param_name} ({info['type']}, {req})\")\n",
    "                    desc += f\"\\n  Parameters: {', '.join(param_list)}\"\n",
    "            \n",
    "            tool_descriptions.append(desc)\n",
    "        \n",
    "        tools_text = \"\\n\".join(tool_descriptions)\n",
    "        \n",
    "        if agent_name == \"Python Coder\":\n",
    "            message = \"You are a Python programming assistant with code execution capabilities.\\n\\n\"\n",
    "            message += \"Available tools:\\n\"\n",
    "            message += tools_text + \"\\n\\n\"\n",
    "            message += \"Python REPL Instructions:\\n\"\n",
    "            message += \"- The python_repl tool executes Python code and returns the output\\n\"\n",
    "            message += \"- To see results, you MUST use print() statements or put expressions as the last line\\n\"\n",
    "            message += \"- Variables persist between executions in the same session\\n\"\n",
    "            message += \"- Always include print statements for intermediate results\\n\"\n",
    "            message += \"- For data analysis or visualizations, always explicitly print results\\n\\n\"\n",
    "            message += \"General Instructions:\\n\"\n",
    "            message += \"- Write clean, well-commented Python code\\n\"\n",
    "            message += \"- Always execute code using the python_repl tool to show results\\n\"\n",
    "            message += \"- Use bash_command for system operations like installing packages\\n\"\n",
    "            message += \"- Explain your code and results clearly\"\n",
    "            return message\n",
    "        \n",
    "        elif agent_name == \"Data Analyst\":\n",
    "            message = \"You are a data analyst assistant with access to various analysis tools.\\n\\n\"\n",
    "            message += \"Available tools:\\n\"\n",
    "            message += tools_text + \"\\n\\n\"\n",
    "            message += \"Python REPL Instructions:\\n\"\n",
    "            message += \"- ALWAYS use print() to display results, dataframes, statistics, etc.\\n\"\n",
    "            message += \"- For pandas DataFrames: use print(df), print(df.head()), print(df.describe())\\n\"\n",
    "            message += \"- For plots: use plt.show() after creating visualizations\\n\"\n",
    "            message += \"- Variables persist between executions\\n\\n\"\n",
    "            message += \"General Instructions:\\n\"\n",
    "            message += \"- Always use the appropriate tool when asked\\n\"\n",
    "            message += \"- For tools with parameters, use the exact parameter names as shown\\n\"\n",
    "            message += \"- Combine multiple tools when needed for complex analysis\\n\"\n",
    "            message += \"- Provide clear explanations of your findings\\n\"\n",
    "            message += \"- Use python_repl for data processing and visualization\\n\"\n",
    "            message += \"- Use bash_command for file operations\"\n",
    "            return message\n",
    "        \n",
    "        else:\n",
    "            message = \"You are a helpful \" + agent_name + \" with access to various tools.\\n\\n\"\n",
    "            message += \"Available tools:\\n\"\n",
    "            message += tools_text + \"\\n\\n\"\n",
    "            message += \"Instructions:\\n\"\n",
    "            message += \"- Use tools whenever they can help answer questions\\n\"\n",
    "            message += \"- For tools with parameters, use the exact parameter names as specified\\n\"\n",
    "            message += \"- Pay close attention to whether a parameter is required or optional\\n\"\n",
    "            message += \"- Provide clear and helpful responses\\n\"\n",
    "            message += \"- Explain what tools you're using and why\"\n",
    "            return message\n",
    "    \n",
    "    def process_message(self, audio_input, text_input, agent_name, history, tts_enabled):\n",
    "        \"\"\"Process user message\"\"\"\n",
    "        try:\n",
    "            # Get input\n",
    "            if audio_input is not None:\n",
    "                input_text = self.audio.transcribe(audio_input)\n",
    "            else:\n",
    "                input_text = text_input\n",
    "            \n",
    "            if not input_text.strip():\n",
    "                return None, history, \"\", \"No input detected\"\n",
    "            \n",
    "            logger.info(f\"Processing: '{input_text[:50]}...' with {agent_name}\")\n",
    "            \n",
    "            # Get response from agent\n",
    "            response = self._run_agent(agent_name, input_text, history)\n",
    "            \n",
    "            # Generate audio if enabled\n",
    "            audio_response = None\n",
    "            if self.audio.has_tts and tts_enabled and len(response) < 1000:\n",
    "                audio_response = self.audio.speak(response[:500])\n",
    "            \n",
    "            # Update history\n",
    "            new_history = history + [\n",
    "                {\"role\": \"user\", \"content\": input_text},\n",
    "                {\"role\": \"assistant\", \"content\": response}\n",
    "            ]\n",
    "            \n",
    "            return audio_response, new_history, \"\", input_text\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Processing error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None, history, \"\", f\"Error: {str(e)}\"\n",
    "    \n",
    "    def _run_agent(self, agent_name: str, message: str, history: List) -> str:\n",
    "        \"\"\"Run agent with proper async handling\"\"\"\n",
    "        if agent_name not in self.agents:\n",
    "            return f\"Agent '{agent_name}' not found\"\n",
    "        \n",
    "        executor = self.agents[agent_name][\"executor\"]\n",
    "        \n",
    "        # Build chat history\n",
    "        chat_history = []\n",
    "        for h in history[-10:]:  # Last 10 messages\n",
    "            if h[\"role\"] == \"user\":\n",
    "                chat_history.append(HumanMessage(content=h[\"content\"]))\n",
    "            else:\n",
    "                chat_history.append(AIMessage(content=h[\"content\"]))\n",
    "        \n",
    "        try:\n",
    "            # Use sync invoke to avoid event loop issues\n",
    "            logger.info(f\"Invoking agent executor for: {message[:50]}...\")\n",
    "            \n",
    "            result = executor.invoke({\n",
    "                \"input\": message,\n",
    "                \"chat_history\": chat_history\n",
    "            })\n",
    "            \n",
    "            logger.info(f\"Agent executor returned: {type(result)}\")\n",
    "            \n",
    "            # Extract response\n",
    "            if isinstance(result, dict):\n",
    "                # Log intermediate steps if available\n",
    "                if \"intermediate_steps\" in result:\n",
    "                    for step in result[\"intermediate_steps\"]:\n",
    "                        if len(step) >= 2:\n",
    "                            action, observation = step[0], step[1]\n",
    "                            logger.info(f\"Tool used: {action.tool if hasattr(action, 'tool') else 'unknown'}\")\n",
    "                            logger.info(f\"Tool result: {str(observation)[:200]}...\")\n",
    "                \n",
    "                # Return the output\n",
    "                return result.get(\"output\", \"No response generated\")\n",
    "            else:\n",
    "                return str(result)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Agent execution error: {e}\", exc_info=True)\n",
    "            return f\"Error executing agent: {str(e)}\"\n",
    "    \n",
    "    def create_interface(self):\n",
    "        \"\"\"Create Gradio interface\"\"\"\n",
    "        with gr.Blocks(\n",
    "            title=\"Enhanced Multi-Agent Voice Assistant\",\n",
    "            theme=gr.themes.Soft()\n",
    "        ) as interface:\n",
    "            gr.Markdown(\"# 🤖 Enhanced Multi-Agent Voice Assistant with MCP Tools\")\n",
    "            gr.Markdown(\"Features: Python REPL, Bash commands, and MCP tool integration\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    agent_dropdown = gr.Dropdown(\n",
    "                        choices=[c[\"name\"] for c in self.agent_configs],\n",
    "                        value=self.agent_configs[0][\"name\"],\n",
    "                        label=\"Select Agent\"\n",
    "                    )\n",
    "                    \n",
    "                    max_iterations_slider = gr.Slider(\n",
    "                        minimum=1,\n",
    "                        maximum=10,\n",
    "                        value=self.max_iterations,\n",
    "                        step=1,\n",
    "                        label=\"Max Iterations\",\n",
    "                        info=\"Maximum number of tool calls the agent can make\"\n",
    "                    )\n",
    "                    \n",
    "                    agent_info = gr.Markdown(\"\")\n",
    "                    \n",
    "                    if self.audio.has_stt:\n",
    "                        audio_input = gr.Audio(\n",
    "                            sources=[\"microphone\"],\n",
    "                            type=\"numpy\",\n",
    "                            label=\"🎤 Voice Input\"\n",
    "                        )\n",
    "                    else:\n",
    "                        audio_input = None\n",
    "                    \n",
    "                    text_input = gr.Textbox(\n",
    "                        label=\"Text Input\",\n",
    "                        placeholder=\"Type your message...\",\n",
    "                        lines=3\n",
    "                    )\n",
    "                    \n",
    "                    send_btn = gr.Button(\"Send\", variant=\"primary\")\n",
    "                    \n",
    "                    if self.audio.has_tts:\n",
    "                        tts_toggle = gr.Checkbox(\n",
    "                            label=\"Enable Text-to-Speech\",\n",
    "                            value=True\n",
    "                        )\n",
    "                        audio_output = gr.Audio(\n",
    "                            label=\"Voice Response\",\n",
    "                            type=\"numpy\",\n",
    "                            autoplay=True\n",
    "                        )\n",
    "                    else:\n",
    "                        tts_toggle = gr.State(False)\n",
    "                        audio_output = None\n",
    "                \n",
    "                with gr.Column(scale=2):\n",
    "                    chatbot = gr.Chatbot(\n",
    "                        label=\"Conversation\",\n",
    "                        height=600\n",
    "                    )\n",
    "                    \n",
    "                    last_input = gr.Textbox(\n",
    "                        label=\"Last Input\",\n",
    "                        interactive=False\n",
    "                    )\n",
    "                    \n",
    "                    clear_btn = gr.Button(\"Clear Chat\")\n",
    "            \n",
    "            # State\n",
    "            history_state = gr.State([])\n",
    "            \n",
    "            # Update max iterations when slider changes\n",
    "            def update_max_iterations(value):\n",
    "                self.max_iterations = value\n",
    "                # Update all existing executors\n",
    "                for agent_name, agent_data in self.agents.items():\n",
    "                    agent_data[\"executor\"].max_iterations = value\n",
    "                return f\"Max iterations set to {value}\"\n",
    "            \n",
    "            max_iterations_slider.change(\n",
    "                update_max_iterations,\n",
    "                inputs=[max_iterations_slider],\n",
    "                outputs=[gr.State()]  # Just update internally\n",
    "            )\n",
    "            \n",
    "            # Update agent info\n",
    "            def show_agent_info(name):\n",
    "                agent = self.agents.get(name, {})\n",
    "                tools = agent.get(\"tools\", [])\n",
    "                tool_info = []\n",
    "                \n",
    "                for t in tools:\n",
    "                    info = f\"**{t.name}**\"\n",
    "                    if t.name in self.mcp_tools_info:\n",
    "                        params = self.mcp_tools_info[t.name].get(\"params\", {})\n",
    "                        if params:\n",
    "                            param_list = [f\"{p} ({info['type']})\" for p, info in params.items()]\n",
    "                            info += f\" - Params: {', '.join(param_list)}\"\n",
    "                    tool_info.append(info)\n",
    "                \n",
    "                return f\"**{name}**\\n\\nAvailable Tools:\\n\" + \"\\n\".join(tool_info)\n",
    "            \n",
    "            agent_dropdown.change(\n",
    "                show_agent_info,\n",
    "                inputs=[agent_dropdown],\n",
    "                outputs=[agent_info]\n",
    "            )\n",
    "            \n",
    "            # Process message\n",
    "            send_btn.click(\n",
    "                fn=self.process_message,\n",
    "                inputs=[\n",
    "                    audio_input if audio_input else gr.State(None),\n",
    "                    text_input,\n",
    "                    agent_dropdown,\n",
    "                    history_state,\n",
    "                    tts_toggle\n",
    "                ],\n",
    "                outputs=[\n",
    "                    audio_output if audio_output else gr.State(None),\n",
    "                    history_state,\n",
    "                    text_input,\n",
    "                    last_input\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Update chat\n",
    "            history_state.change(\n",
    "                fn=lambda h: [(m[\"content\"], None) if m[\"role\"] == \"user\" \n",
    "                             else (None, m[\"content\"]) for m in h],\n",
    "                inputs=[history_state],\n",
    "                outputs=[chatbot]\n",
    "            )\n",
    "            \n",
    "            # Clear\n",
    "            clear_btn.click(\n",
    "                fn=lambda: ([], [], \"\", \"\"),\n",
    "                outputs=[chatbot, history_state, text_input, last_input]\n",
    "            )\n",
    "            \n",
    "            # Initialize\n",
    "            interface.load(\n",
    "                fn=lambda: show_agent_info(self.agent_configs[0][\"name\"]),\n",
    "                outputs=[agent_info]\n",
    "            )\n",
    "        \n",
    "        return interface\n",
    "    \n",
    "    def _cleanup(self):\n",
    "        \"\"\"Cleanup resources\"\"\"\n",
    "        logger.info(\"Cleaning up...\")\n",
    "        \n",
    "        # Cleanup MCP\n",
    "        if self.cleanup_func and self.mcp_loop:\n",
    "            try:\n",
    "                future = asyncio.run_coroutine_threadsafe(\n",
    "                    self.cleanup_func(),\n",
    "                    self.mcp_loop\n",
    "                )\n",
    "                future.result(timeout=5)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Cleanup error: {e}\")\n",
    "        \n",
    "        # Stop MCP event loop\n",
    "        if self.mcp_loop:\n",
    "            self.mcp_loop.call_soon_threadsafe(self.mcp_loop.stop)\n",
    "            if self.mcp_thread:\n",
    "                self.mcp_thread.join(timeout=2)\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    MCP_SERVERS = {\n",
    "        \"local_http\": {\"url\": \"http://127.0.0.1:8000/mcp\"}\n",
    "    }\n",
    "    \n",
    "    AGENT_CONFIGS = [\n",
    "        {\n",
    "            \"name\": \"Data Analyst\",\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"temperature\": 0.3,\n",
    "            \"description\": \"Data analysis with all available tools\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Python Coder\",\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"temperature\": 0.2,\n",
    "            \"description\": \"Python programming with code execution\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Assistant\",\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"temperature\": 0.7,\n",
    "            \"description\": \"General assistant with MCP tools\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # You can set max_iterations here (default is 5)\n",
    "    dashboard = EnhancedMCPDashboard(MCP_SERVERS, AGENT_CONFIGS, max_iterations=5)\n",
    "    interface = dashboard.create_interface()\n",
    "    interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
